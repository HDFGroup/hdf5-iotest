; Sample config file for hdf5_iotest.c
; Overwrite the default values by defining your own sections!
[DEFAULT]
version = 0                ; Let's keep an open mind!
steps = 20                 ; Number of steps
arrays = 500               ; Number of arrays
rows = 100                 ; Total number of array rows for strong scaling
                           ; Number of array rows per block for weak scaling
columns = 200              ; Total number of array columns for strong scaling
                           ; Number of array columns per block for weak scaling
process-rows = 1           ; Number of MPI-process rows:
                           ; rows % proc-rows == 0 for strong scalingx
process-columns = 1        ; Number of MPI-process columns:
                           ; columns % proc-columns == 0 for strong scaling
scaling = weak             ; Scaling ([weak, strong])
dataset-rank = 4           ; Rank of the dataset(s) in the file ([2, 3, 4])
slowest-dimension = step   ; Slowest changing dimension ([step, array])
layout = contiguous        ; HDF5 dataset layout ([contiguous, chunked])
mpi-io = independent       ; MPI I/O mode ([independent, collective])
hdf5-file = hdf5_iotest.h5 ; HDF5 output file name
csv-file = hdf5_iotest.csv ; CSV results file name
